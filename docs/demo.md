# <small>Demo</small> 

My research experience focuses primarily on theoretical contributions, and I show selected demos here, more coming soon...



##<small>Smart interaction</small> 
<div align="center">
<img src="/media/smartInteraction.jpg" width="500" height="auto">
</div>

Cybersickness is an annoying issue in locomotion-dominated VR applications, while the online evaluation of cybersickness during the use of VR will benefit many developers and researchers. Currently, an approach to evaluating cybersickness is using subjective questionnaires (e.g., SSQ), but the questionnaire-based evaluation will interrupt the experiment and introduce huge individual variances. Can we develop some tools to report cybersickness in real-time according to physiological signals such as EDA, Heart rate, EEG, Posture sway, etc.? Which feature can be extracted as the best online cybersickness indicator? Can artificial intelligence algorithms work? How can we validate its performance?


----


##<small>Cybersickness prediction involving human factors</small> 
<div align="center">
<img src="/media/prediction.jpg" width="600" height="auto">
</div>
Y. Wang, J.-R. Chardonnet, F. Merienne, and J. Ovtcharova, “Using Fuzzy Logic to Involve Individual Differences for Predicting Cybersickness during VR Navigation,” in 2021 IEEE VR, Mar. 2021, pp. 373–381.


----

<br/> 

##<small>VR sickness prediction with LSTM</small> 
<div align="center">
<img src="/media/autoencoder.jpg" width="600" height="auto">
</div>

Y. Wang, J.-R. Chardonnet, and F. Merienne, “VR Sickness Prediction for Navigation in Immersive Virtual Environments using a Deep Long Short Term Memory Model,” in 2019 IEEE VR, Mar. 2019, pp. 1874–1881.


----

<br/> 

##<small>Semi-automatic navigation</small>

<div align="center">
<video id="video" width="500" height="250"  controls="controls" preload="auto" poster="">
      <source id="mp4" src="/media/semiAutomaticNavigation.mp4" type="video/mp4">
</videos>
</div>

Y. Wang, J.-R. Chardonnet, and F. Merienne, “Design of a Semiautomatic Travel Technique in VR Environments,” in 2019 IEEE VR, Mar. 2019, pp. 1223–1224.

----

<br/> 

##<small>Classification of dyeing type</small>

<div align="center">
<img src="/media/fiberClassification.jpg" width="600" height="auto">
</div>

This is GUI software developed for a textile company. The existing approach in this company relies on workers to distinguish different types of dyeing and finishing fabrics with microscope images, which is inefficient. The classification algorithm can automatically recognize the fabric type with more efficiency. The source code is written in Python (OpenCV for image processing, Scikit-learn for classification) and then compiled to a platform-independent binary file. 

----



<!-- 地球仪统计访客信息-->
<div align="center">
<script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5d4f8mo2j0d&amp;m=7&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33&amp;s=280" async="async"></script>
</div>





<!-- 通过邮箱联系我： contact form-->
<script src="https://apps.elfsight.com/p/platform.js" defer></script>
<div class="elfsight-app-602f8d4e-e7e1-4a75-9aac-df3739b01748"></div>



<!-- Go to www.addthis.com/dashboard to customize your tools -->
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-6001d169567f8288"></script>

